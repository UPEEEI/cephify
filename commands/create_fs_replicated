#/bin/bash
echo "create_volume"
echo "This will create RADOS pools for Data and Metadata on MDS node using ceph fs volume. If you want to delete existing data and metadata pool, run destroy_volume"
sleep 1
echo "Do you want to create a Ceph data and metadata pool on $1? Make sure a cluster already exists"
select yn in "Yes" "No"; do
    case $yn in
        Yes ) break;;
        No ) exit;;
    esac
done

echo "Enabling multiple filesystems creation"
sleep 1
ssh $1 "ceph fs flag set enable_multiple true --yes-i-really-mean-it"

read -p "Enter volume name [no space]: " VOLUME

echo "Creating volume $VOLUME..."
sleep 1
ssh $1 "ceph fs volume create $VOLUME"

echo "Checking cephfs..."
sleep 1
ssh $1 "ceph fs ls"

echo "Checking metadata node status..."
sleep 1
ssh $1 "ceph mds stat"

echo "Checking cephfs status..."
sleep 3
ssh $1 "ceph fs status $VOLUME"

echo "Set replication size and min_size for I/O:"
sleep 1
read -p "Enter replication size [3 - default(two extra copies), 2 - (one extra copy) ]: " REPL_SIZE
read -p "Enter min_size for I/O to start running [recommended value > 1]: " MIN_SIZE

echo "Setting parameters..."
sleep 1
ssh $1 "ceph osd pool set cephfs.$VOLUME.data size $REPL_SIZE"
ssh $1 "ceph osd pool set cephfs.$VOLUME.data min_size $MIN_SIZE"
ssh $1 "ceph osd pool set cephfs.$VOLUME.meta size $REPL_SIZE"
ssh $1 "ceph osd pool set cephfs.$VOLUME.meta min_size $MIN_SIZE"

ssh $1 "ceph osd dump | grep 'replicated size'"


